{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - **Zomato Restaurant Clustering and Sentiment Analysis**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zomato, a start-up for food delivery and restaurant aggregation, was established in 2008 by Deepinder Goyal and Pankaj Chaddah in India. Zomato offers details like menus and user-feedback for eateries, along with food delivery services in specific cities through partnered restaurants. India is well-known for its wide variety of cuisine served in numerous restaurants and hotels, showcasing the theme of diversity within unity. The restaurant industry in India is constantly changing. An increasing number of Indians are becoming more receptive to the concept of consuming restaurant meals, whether by dining out or ordering delivery. The increasing amount of dining establishments in each region of India has inspired a thorough analysis of data to uncover unique findings and statistics about the food industry in every urban area. Therefore, the main objective of this project is to analyze the restaurant information from Zomato for every city in India.\n",
        "\n",
        "The Project concentrates on analyzing customer reviews in the data to draw conclusions through Visualizations for both Customers and Company. Additionally, categorize the zomato restaurants into various segments. The data is displayed visually, making it simple to analyze data immediately. The examination also addresses certain business scenarios that can assist customers in discovering the top restaurant in their area and enable the company to improve and focus on areas where they are currently lacking. This might aid in grouping the restaurants into categories. The data contains important details about food type and pricing, which can be utilized for cost-benefit analysis and sentiment analysis. Additionally, reviewers' metadata can be utilized to distinguish critics in the field.\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write Problem Statement Here.**\n",
        "\n",
        "In the ever-changing Indian restaurant scene, Zomato, a leading restaurant aggregator and food delivery platform, has gathered a large dataset showcasing a variety of culinary experiences in various cities. The difficulty is in analyzing valuable information from this abundant dataset to help customers and the company.\n",
        "\n",
        "1.Customer Sentiment Analysis\n",
        "\n",
        "The project's goal is to explore the feelings conveyed by customers in their reviews. Through the use of sentiment analysis methods, our goal is to assess the general satisfaction levels of customers towards the restaurants featured on Zomato. This evaluation will offer practical information about the strengths and weaknesses of various establishments, assisting potential diners in making informed decisions and helping Zomato improve its user experience.\n",
        "\n",
        "2.Restaurant Clustering\n",
        "\n",
        "Another crucial element of the project is the task of grouping together Zomato's extensive database of restaurants. Our goal is to cluster restaurants with similar features, such as cuisine types, pricing, and user ratings, using suitable clustering algorithms. This division will help Zomato better grasp the restaurant industry and provide important data for tackling business problems.\n",
        "\n",
        "3.Business Case Solutions\n",
        "\n",
        "The information obtained from analyzing customer opinions and grouping restaurants will help address multiple business scenarios. It will help customers find the top restaurants in their area through reviews from other customers. At the same time, Zomato's analysis will identify both areas for improvement and potential for growth, helping the company enhance its services and meet changing customer preferences.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import math\n",
        "from numpy import loadtxt\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import missingno\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "restaurant_data = pd.read_csv('/content/drive/MyDrive/Zomato Restaurant names and Metadata.csv')\n",
        "reviews = pd.read_csv('/content/drive/MyDrive/Zomato Restaurant reviews.csv')"
      ],
      "metadata": {
        "id": "cRMOD4eL7f_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"restaurant_data shape:\",restaurant_data.shape)\n",
        "print(\"reviews shape:\",reviews.shape)"
      ],
      "metadata": {
        "id": "Hp3y3J0X74j3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "restaurant_data.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews.head()"
      ],
      "metadata": {
        "id": "24olKr6q8HDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset Information\n",
        "restaurant_data.info()"
      ],
      "metadata": {
        "id": "UExf_vTM8JJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews.info()"
      ],
      "metadata": {
        "id": "ZGJrx72f8Zdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Duplicate Values"
      ],
      "metadata": {
        "id": "0mlXchKS8gGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for duplicates\n",
        "print(\"Duplicates in restaurant_data:\",restaurant_data.duplicated().sum())\n",
        "print(\"Duplicates in reviews:\",reviews.duplicated().sum())"
      ],
      "metadata": {
        "id": "8yxbyCtJ8b7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(\"Missing values in restaurant_data:\")\n",
        "print(restaurant_data.isnull().sum(),\"\\n\")\n",
        "print(\"Missing values in reviews:\")\n",
        "print(reviews.isnull().sum())"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "missingno.matrix(restaurant_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missingno.matrix(reviews)"
      ],
      "metadata": {
        "id": "cRC9dnpW9KPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Restaurants data\n",
        "\n",
        "The restaurants data consists of information about 105 restaurants with 6 features.\n",
        "\n",
        "In the column \"Collections\" 52% of values are missing\n",
        "\n",
        "####Reviews data\n",
        "\n",
        "The reviews data cosists of information about 10000 reviews about the 105 restaurants with 7 features.\n",
        "\n",
        "In the columns \"Reviewer\",\"Review\",\"Rating\",\"Metadata\",\"Time\" <0.5% of the data is missing\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "print(\"Features in restaurent data: \",restaurant_data.columns.tolist())\n",
        "print(\"Features in review data: \",reviews.columns.tolist())"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "restaurant_data.describe(include='all')\n",
        "\n"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews.describe(include='all')"
      ],
      "metadata": {
        "id": "OsP3n_Ka9xxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Restaurant Data:\n",
        "-Name: Name of Restaurants\n",
        "\n",
        "-Links: URL Links of Restaurants\n",
        "\n",
        "-Cost: Per person estimated cost of dining\n",
        "\n",
        "-Collection: Tagging of Restaurants w.r.t. Zomato categories\n",
        "\n",
        "-Cuisines: Cuisines served by restaurants\n",
        "\n",
        "-Timings: Restaurant timings\n",
        "\n",
        "###Review Data:\n",
        "-Reviewer: Name of the reviewer\n",
        "\n",
        "-Review: Review text\n",
        "\n",
        "-Rating: Rating provided\n",
        "\n",
        "-MetaData: Reviewer metadata - Number of reviews and followers\n",
        "\n",
        "-Time: Date and Time of Review\n",
        "\n",
        "-Pictures: Number of pictures posted with review"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in restaurant_data.columns.tolist():\n",
        "  print(\"Unique\",i,\":\",restaurant_data[i].nunique(),\"\\n\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in reviews.columns.tolist():\n",
        "  print(\"Unique\",i,\":\",reviews[i].nunique(),\"\\n\")"
      ],
      "metadata": {
        "id": "X8-8lMhz-n-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Dropping collections column since most of the values are null\n",
        "restaurant_data.drop(\"Collections\",axis=1,inplace=True)\n",
        "\n",
        "# Dropping remaining null values from restaurant_data and reviews since they are very few\n",
        "restaurant_data.dropna(inplace=True)\n",
        "reviews.dropna(inplace=True)\n",
        "\n",
        "# Check for missing values After handling\n",
        "print(\"Missing values in restaurant_data:\")\n",
        "print(restaurant_data.isnull().sum(),\"\\n\")\n",
        "print(\"Missing values in reviews:\")\n",
        "print(reviews.isnull().sum())"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop duplicate rows\n",
        "restaurant_data.drop_duplicates(inplace=True)\n",
        "reviews.drop_duplicates(inplace=True)\n",
        "print(\"restaurant_data shape:\",restaurant_data.shape)\n",
        "print(\"reviews shape:\",reviews.shape)"
      ],
      "metadata": {
        "id": "G7FTzIs7_OEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets extract cuisines from the Cuisines(string) column and store as a list\n",
        "print(\"Cuisines data Before preprocessing:\\n\")\n",
        "print(restaurant_data.Cuisines[0])\n",
        "print(\"\\nCuisines data After preprocessing:\\n\")\n",
        "print(\"\",restaurant_data.Cuisines[0].lower().replace(\" \",\"\").split(\",\"))"
      ],
      "metadata": {
        "id": "RSAcc-lB_RpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets apply the preprocessing steps on the Cuisines column\n",
        "restaurant_data[\"Cuisines_list\"] = restaurant_data.Cuisines.apply(lambda x: x.lower().replace(\" \",\"\").split(\",\"))\n",
        "\n",
        "# Lets check the names of count of unique cuisines\n",
        "cusines_set = set()\n",
        "for cuisines in restaurant_data.Cuisines_list:\n",
        "  cusines_set.update(cuisines)\n",
        "print(\"Total number of unique cuisines: \",len(cusines_set))\n",
        "cusines_set"
      ],
      "metadata": {
        "id": "kGdt81tu_wjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess and convert the cost column to int data type\n",
        "restaurant_data.Cost = restaurant_data.Cost.apply(lambda x: x.replace(\",\",\"\")).astype(int)\n",
        "restaurant_data.Cost"
      ],
      "metadata": {
        "id": "Th1ZrF1-_0YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "restaurant_data.Cost.describe()"
      ],
      "metadata": {
        "id": "3waQVycd_8k0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "restaurant_data[[\"Name\",\"Cost\",\"Cuisines_list\"]]"
      ],
      "metadata": {
        "id": "JTdqi_0__-VR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling on Reviews"
      ],
      "metadata": {
        "id": "ZC8rfU3lAJr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# replace non numbers with NAN\n",
        "reviews.Rating = pd.to_numeric(reviews.Rating, errors='coerce')\n"
      ],
      "metadata": {
        "id": "hcIAZo0MACsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews.Rating.fillna(reviews.Rating.mean(), inplace=True)"
      ],
      "metadata": {
        "id": "UjHfBw1wAd0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the Metadata column to create a regex expression\n",
        "followers = reviews.Metadata.apply(lambda x: x.split(\",\")[-1])\n",
        "print(followers.apply(lambda x: x.split(\" \")[-1]).value_counts())\n",
        "\n",
        "review_count = reviews.Metadata.apply(lambda x: x.split(\",\")[0])\n",
        "print(review_count.apply(lambda x: x.split(\" \")[-1]).value_counts())\n"
      ],
      "metadata": {
        "id": "hvVepjoGAhw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def extract_follower_and_review_count(text):\n",
        "\n",
        "    # Define regular expressions for review and followers\n",
        "    review_pattern = r'(\\d+) Review'\n",
        "    followers_pattern = r'(\\d+) Follower'\n",
        "\n",
        "    # Search for the review and followers using regex\n",
        "    review_match = re.search(review_pattern, text)\n",
        "    followers_match = re.search(followers_pattern, text)\n",
        "\n",
        "    # Extract the review and followers values\n",
        "    review = review_match.group(1) if review_match else 0\n",
        "    followers = followers_match.group(1) if followers_match else 0\n",
        "    return [review, followers]\n",
        "\n",
        "extract_follower_and_review_count(\"1 Review , 22 Follower\")\n"
      ],
      "metadata": {
        "id": "Zps_EklgAm-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews[['prev_reviews_count', 'followers_count']] = reviews['Metadata'].apply(extract_follower_and_review_count).apply(pd.Series)\n"
      ],
      "metadata": {
        "id": "80yAkBU1Ase3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews.drop('Metadata', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "WBzNpXbbA2Bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_restaurant_data = pd.merge(reviews, restaurant_data[[\"Name\",\"Cost\",\"Cuisines_list\"]], left_on='Restaurant', right_on='Name')\n",
        "merged_restaurant_data"
      ],
      "metadata": {
        "id": "ICY2qhBRA5-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?\n",
        "-Dropped missing values and duplicates\n",
        "\n",
        "-Extracted cuisines from the Cuisines column\n",
        "\n",
        "-Converted cost column to int data type\n",
        "\n",
        "#### Insights\n",
        "-There are 44 unique cuisines across 104 restaurants\n",
        "\n",
        "-Estimated cost of dining of all 104 restaurents are in the range 150 Rs to 2800 Rs\n",
        "\n",
        "-Extracting the locations from the links column we can observe that all restaurents are from Gachibowli, Hyderabad\n"
      ],
      "metadata": {
        "id": "0VKW37ybBHuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1 Distribution of Cost (Univariate)"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "# Bivariate with Categorical - Numerical\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data=restaurant_data, x='Cost', kde=True, color='skyblue')\n",
        "plt.title('Restaurant Cost Distribution')\n",
        "plt.xlabel('Cost')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\",restaurant_data['Cost'].describe())"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-The average cost per person is 861 Rs With a std. deviation of 515 Rs\n",
        "\n",
        "-Min observed cost is 150 and max is 2800"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2 Distribution of Rating (Univariate)"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data = reviews, x = 'Rating', kde = True, color = 'skyblue')\n",
        "\n",
        "print(\"\\n\",reviews['Rating'].describe())"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-The average rating is 3.6 indicating a majority of postitive ratings\n",
        "\n",
        "-We can see two peaks in the distribution at 1 and 5 indicating that customers tend to have strong opinions about their experiences, either very good or very bad, rather than neutral or average."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3 Most popular cuisines (Univariate)"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "\n",
        "all_cuisines = []\n",
        "\n",
        "for cuisine_list in restaurant_data.Cuisines_list:\n",
        "    for cuisine in cuisine_list:\n",
        "        all_cuisines.append(cuisine)\n",
        "\n",
        "# Count the occurrences of each cuisine type\n",
        "cuisine_counts = pd.Series(all_cuisines).value_counts()\n",
        "\n",
        "# Choose the top N cuisine types to display on the y-axis\n",
        "top_n = 10  # You can change this number as needed\n",
        "cuisine_counts = cuisine_counts.head(top_n)\n",
        "\n",
        "# custom color palette\n",
        "colors = ['skyblue', 'lightcoral', 'lightgreen', 'lightsalmon', 'lightseagreen', 'lightpink', 'lightsteelblue', 'lightgoldenrodyellow', 'lightcyan', 'lightgray']\n",
        "\n",
        "# Create the bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.barh(cuisine_counts.index, cuisine_counts.values, color=colors)\n",
        "\n",
        "# Add labels to the bars\n",
        "for bar in bars:\n",
        "    width = bar.get_width()\n",
        "    plt.text(width, bar.get_y() + bar.get_height()/2, f'{width}', ha='left', va='center', fontsize=12, color='black')\n",
        "\n",
        "plt.title('Top {} Cuisine Types in Restaurants'.format(top_n))\n",
        "plt.xlabel('Number of Restaurants')\n",
        "plt.ylabel('Cuisine Type')\n",
        "plt.gca().invert_yaxis()  # Invert the y-axis to display the most common cuisine at the top\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Northindian seems to be the most popular cuisine and south indian and bakery to be the least popular"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4 Restaurant Costs vs cuisines"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a new DataFrame with cuisine types and corresponding costs\n",
        "cuisine_cost_df = pd.DataFrame({\n",
        "    'Cuisine Type': restaurant_data.Cuisines_list.explode(),\n",
        "    'Cost': restaurant_data['Cost']\n",
        "})\n",
        "\n",
        "# Count the occurrences of each cuisine type and select the top 20\n",
        "top_20_cuisines = cuisine_cost_df['Cuisine Type'].value_counts().head(20).index\n",
        "\n",
        "# Filter the DataFrame to include only the top 20 cuisines\n",
        "cuisine_cost_df_top_20 = cuisine_cost_df[cuisine_cost_df['Cuisine Type'].isin(top_20_cuisines)]\n",
        "\n",
        "# Calculate the average cost for each cuisine type and sort by average cost\n",
        "average_cost_by_cuisine = cuisine_cost_df_top_20.groupby('Cuisine Type')['Cost'].median().sort_values(ascending=False).reset_index()\n",
        "\n",
        "# Custom color palette\n",
        "colors = ['skyblue', 'lightcoral', 'lightgreen', 'lightsalmon', 'lightseagreen', 'lightpink', 'lightsteelblue', 'lightgoldenrodyellow', 'lightcyan', 'lightgray']\n",
        "\n",
        "# Create the bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.barh(average_cost_by_cuisine['Cuisine Type'], average_cost_by_cuisine['Cost'], color=colors)\n",
        "\n",
        "# Add labels to the bars\n",
        "for bar in bars:\n",
        "    width = bar.get_width()\n",
        "    plt.text(width, bar.get_y() + bar.get_height()/2, f'{width}', ha='left', va='center', fontsize=12, color='black')\n",
        "\n",
        "plt.title('Median Cost by Cuisine Type')\n",
        "plt.xlabel('Median Cost')\n",
        "plt.ylabel('Cuisine Type')\n",
        "plt.gca().invert_yaxis()  # Invert the y-axis to display the highest median cost at the top\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5 Affordable and Expensive Restaurents (Bivariate)"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "# Sort the DataFrame by cost in ascending order (affordable to expensive)\n",
        "affordable_restaurants = restaurant_data.sort_values(by='Cost', ascending=False).tail(20)\n",
        "\n",
        "# Sort the DataFrame by cost in descending order (expensive to affordable)\n",
        "expensive_restaurants = restaurant_data.sort_values(by='Cost', ascending=False).head(20)\n",
        "\n",
        "# Concatenate both DataFrames to create a single DataFrame with the top 20 affordable and top 20 expensive restaurants\n",
        "top_restaurants = pd.concat([expensive_restaurants,affordable_restaurants])\n",
        "\n",
        "# Create a bar plot to visualize the top 20 affordable and top 20 expensive restaurants\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.barh(top_restaurants['Name'], top_restaurants['Cost'], color='skyblue')\n",
        "plt.title('Top 20 Affordable and Expensive Restaurants')\n",
        "plt.xlabel('Cost')\n",
        "plt.ylabel('Restaurant Name')\n",
        "plt.gca().invert_yaxis()  # Invert the y-axis to show the highest cost at the top\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n Statistics for top 20 expensive restaurants\")\n",
        "print(expensive_restaurants.describe())\n",
        "print(\"\\n Statistics for top 20 affordable restaurants\")\n",
        "print(affordable_restaurants.describe())\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-The top expensive restaurants are, on average, about 5.4 times more costly than the top affordable restaurants.\n",
        "\n",
        "-This data could help consumers make decisions based on their budget."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6 Variation of Ratings W.R.T time (Bivariate with Categorical - Numerical)\n"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "\n",
        "# Converting 'Time' column to datetime\n",
        "reviews['Time'] = pd.to_datetime(reviews['Time'])\n",
        "\n",
        "# Extracting month, day of the week, and hour\n",
        "reviews['Month'] = reviews['Time'].dt.month\n",
        "reviews['DayOfWeek'] = reviews['Time'].dt.day_name()\n",
        "reviews['Hour'] = reviews['Time'].dt.hour\n",
        "\n",
        "# Seasonal Trend Analysis: Average Rating by Month\n",
        "monthly_avg_rating = reviews.groupby('Month')['Rating'].mean()\n",
        "\n",
        "# Weekly Trend Analysis: Average Rating by Day of the Week\n",
        "weekly_avg_rating = reviews.groupby('DayOfWeek')['Rating'].mean().reindex([\n",
        "    'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'\n",
        "])\n",
        "\n",
        "# Hourly Trend Analysis: Average Rating by Hour of the Day\n",
        "hourly_avg_rating = reviews.groupby('Hour')['Rating'].mean()\n",
        "\n",
        "# Plotting all three trends in a single figure with 3 rows and 1 column\n",
        "fig, axs = plt.subplots(3, 1, figsize=(10, 10))\n",
        "\n",
        "# Monthly Trend Plot\n",
        "axs[0].plot(monthly_avg_rating, color='teal')\n",
        "axs[0].set_title('Average Ratings by Month')\n",
        "axs[0].set_xlabel('Month')\n",
        "axs[0].set_ylabel('Average Rating')\n",
        "axs[0].set_xticks(range(0, 12))\n",
        "axs[0].set_xticklabels([dt.date(2000, m, 1).strftime('%B') for m in range(1, 13)])\n",
        "axs[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Weekly Trend Plot\n",
        "axs[1].plot(weekly_avg_rating, color='purple')\n",
        "axs[1].set_title('Average Ratings by Day of the Week')\n",
        "axs[1].set_xlabel('Day of the Week')\n",
        "axs[1].set_ylabel('Average Rating')\n",
        "axs[1].set_xticks(range(7))\n",
        "axs[1].set_xticklabels(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
        "axs[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Hourly Trend Plot\n",
        "axs[2].plot(hourly_avg_rating, color='orange')\n",
        "axs[2].set_title('Average Ratings by Hour of the Day')\n",
        "axs[2].set_xlabel('Hour of the Day')\n",
        "axs[2].set_ylabel('Average Rating')\n",
        "axs[2].set_xticks(range(0, 24))\n",
        "axs[2].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Average Ratings by Month:\n",
        "-There is a noticeable peak in June, indicating the highest average ratings occur in this month.\n",
        "\n",
        "-There are lower points, particularly noticeable in April and September, suggesting a potential seasonal impact on ratings.\n",
        "\n",
        "#### Average Ratings by Day of the Week:\n",
        "-Ratings peak mid-week, particularly on Wednesday, and then there is a decline towards the weekend.\n",
        "\n",
        "-The lowest average ratings occur on Friday.\n",
        "\n",
        "####Average Ratings by Hour of the Day:\n",
        "-There are peaks in the early hours (around 5 AM), mid-morning (around 9 AM), and late evening (around 8 PM).\n",
        "\n",
        "-There are noticeable dips in the late morning (around 7-8 AM) and early evening (around 2-4 PM).\n",
        "\n",
        "####Business Implications:\n",
        "-Positive Impact: The insights could lead to targeted marketing during peak times, quality control measures when lower ratings are expected, and staffing\n",
        "-adjustments to ensure service quality during critical hours or days.\n",
        "\n",
        "####Strategic Applications:\n",
        "-Seasonal Adjustments: The variation in monthly ratings could suggest that the restaurants should adjust their offerings or operations seasonally, perhaps offering summer specials or comfort food in colder months.\n",
        "\n",
        "-Weekly Planning: Understanding that ratings dip over the weekend could imply that customers have higher expectations or that there are operational challenges during these days.\n",
        "\n",
        "-Hourly Focus: The hourly variations might reflect changes in customer base or staff shifts. Special attention to service quality at known low points, and maintaining the high standards during the peaks, could enhance overall ratings."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7  Variation of Ratings with Cost"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns  # Import seaborn for enhanced styling\n",
        "\n",
        "# Assuming you have already loaded your data and merged it as shown in your code\n",
        "\n",
        "# Create 10 bins for the 'Cost' column\n",
        "merged_restaurant_data['Cost_Bin'] = pd.cut(merged_restaurant_data['Cost'], bins=7)\n",
        "\n",
        "# Set a custom color palette for the plot\n",
        "colors = sns.color_palette(\"Set2\")\n",
        "\n",
        "# Create a box plot with seaborn for better styling\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.set(style=\"whitegrid\")  # Set the style to whitegrid\n",
        "sns.boxplot(x='Cost_Bin', y='Rating', data=merged_restaurant_data, palette=colors)\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Variation of Ratings with Cost')\n",
        "plt.xlabel('Cost Bins')\n",
        "plt.ylabel('Ratings')\n",
        "\n",
        "# Add grid lines to the plot\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Customize the plot further as needed, e.g., adjusting fonts, colors, etc.\n",
        "\n",
        "plt.tight_layout()  # Ensure the plot is well-fit within the figure\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Higher Cost, Higher Ratings: The highest cost bin [(2421, 2800)] shows the highest median rating, which could suggest that more expensive restaurants tend to receive better ratings, possibly due to perceived quality, service, or experience.\n",
        "\n",
        "-Presence of Outliers: There are outliers in both the lower and higher cost bins, indicated by the dots outside the main \"box\" of the box plot. This indicates that there are some restaurants with ratings that are significantly lower than the typical range of ratings for their cost category.\n",
        "\n",
        "####Business Implications:\n",
        "-Positive Impact:\n",
        "The presence of outliers suggests that there is an opportunity for improvement or differentiation for restaurants that are underperforming within their cost category.\n",
        "\n",
        "-Negative Impact:\n",
        "Outliers, especially in the highest cost bin, suggest that high prices alone do not guarantee high ratings. Poor experiences at expensive restaurants may lead to significantly lower ratings due to higher customer expectations associated with higher costs."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Sentiment Analysis"
      ],
      "metadata": {
        "id": "tyV83suNHMPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess text for sentiment analysis"
      ],
      "metadata": {
        "id": "a_LJ3jayHWzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_string(input_string):\n",
        "    cleaned_string = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?|\\d+\", \"\", input_string.lower())\n",
        "    return cleaned_string\n",
        "\n",
        "reviews['Review Cleaned'] = reviews['Review'].apply(clean_string)\n"
      ],
      "metadata": {
        "id": "ZcLvAJTYHO0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate sentiment polarity using TextBlob"
      ],
      "metadata": {
        "id": "OJfG5zpIHf8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Function to get sentiment polarity\n",
        "def get_sentiment(text):\n",
        "    return TextBlob(text).sentiment.polarity\n",
        "\n",
        "# Applying the function to the review column\n",
        "reviews['Sentiment'] = reviews['Review Cleaned'].apply(get_sentiment)\n",
        "\n",
        "# Classifying sentiments into positive, negative, and neutral\n",
        "reviews['Sentiment_Type'] = reviews['Sentiment'].apply(lambda x: 'positive' if x > 0 else ('negative' if x < 0 else 'neutral'))\n",
        "\n",
        "# Displaying the first few rows with the sentiment analysis\n",
        "reviews[['Review Cleaned', 'Sentiment', 'Sentiment_Type']].head()\n"
      ],
      "metadata": {
        "id": "FsrGSkAKHdZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract Noun from each review for further analysis"
      ],
      "metadata": {
        "id": "PFMeHuMuHuvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extract_food_entities(review):\n",
        "    doc = nlp(review)\n",
        "    # Extract noun from text using spacy\n",
        "    food_entities = [token.text for token in doc if token.pos_ == 'NOUN']\n",
        "    return food_entities\n",
        "\n",
        "# Apply the function to each review\n",
        "reviews['Food_Entities'] = reviews['Review Cleaned'].apply(extract_food_entities)\n",
        "\n",
        "# Display the first few rows with extracted food entities\n",
        "reviews[['Review Cleaned', 'Food_Entities']].head()"
      ],
      "metadata": {
        "id": "xjoX5rW9Hxqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews['Food_Entities'].value_counts()"
      ],
      "metadata": {
        "id": "vKR94eRSIdk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating the cumulative sentiment for each entity"
      ],
      "metadata": {
        "id": "RsW5FsDDImI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Initialize dictionaries to hold the sum of values of sentiments for each food item\n",
        "food_sentiment_counts = defaultdict(lambda: {'positive': 0, 'negative': 0, 'neutral': 0})\n",
        "\n",
        "# Iterating through each review\n",
        "for index, row in reviews.iterrows():\n",
        "    sentiment = row['Sentiment_Type']\n",
        "    sentiment_value = row['Sentiment']\n",
        "    for food_item in row['Food_Entities']:\n",
        "        # Get the cumulative sentiment value for this food item\n",
        "        food_sentiment_counts[food_item][sentiment] += sentiment_value\n",
        "\n",
        "# Now, food_sentiment_counts has the sentiment counts for each food item\n",
        "food_sentiment_count_df = pd.DataFrame.from_dict(food_sentiment_counts, orient='index')\n",
        "food_sentiment_count_df"
      ],
      "metadata": {
        "id": "_2JcT5lUIs9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing the results"
      ],
      "metadata": {
        "id": "yIXCd5vNI1yS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the threshold to filter the top values (greater than the 20th highest positive sentiment value)\n",
        "threshold = food_sentiment_count_df['positive'].sort_values(ascending=False)[19]\n",
        "\n",
        "# Filtering the DataFrame\n",
        "top_sentiments_df = food_sentiment_count_df[food_sentiment_count_df['positive'] > threshold].sort_values(by='positive', ascending=False)\n",
        "\n",
        "\n",
        "# Plotting\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Stacked bar chart for positive counts and any other sentiment counts except negative\n",
        "top_sentiments_df[['positive']].plot(kind='bar', stacked=True, ax=ax, color='green')\n",
        "\n",
        "# Line chart for negative values\n",
        "ax2 = ax.twinx()\n",
        "(top_sentiments_df['negative']*(-1)).plot(kind='line', ax=ax2, color='red', marker='o', linewidth=2, label='Negative')\n",
        "\n",
        "# Labels and legend\n",
        "ax.set_xlabel('Food')\n",
        "ax.set_ylabel('Positive Sentiment Value')\n",
        "ax2.set_ylabel('Negative Sentiment Value')\n",
        "ax.set_title('Sentiment Value for Top 20 Entities Sorted by Positive Sentiment')\n",
        "fig.legend(loc='upper right', bbox_to_anchor=(1.1, 1))\n",
        "ax.set_xticklabels(top_sentiments_df.index, rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2EdSOi6-I5Bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the threshold to filter the top values (greater than the 20th highest positive sentiment value)\n",
        "threshold = food_sentiment_count_df['negative'].sort_values(ascending=True)[19]\n",
        "\n",
        "# Filtering the DataFrame\n",
        "top_sentiments_df = food_sentiment_count_df[food_sentiment_count_df['negative'] < threshold].sort_values(by='negative', ascending=True)\n",
        "\n",
        "\n",
        "# Plotting\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Stacked bar chart for positive counts and any other sentiment counts except negative\n",
        "top_sentiments_df[['positive']].plot(kind='bar', stacked=True, ax=ax, color='green')\n",
        "\n",
        "# Line chart for negative values\n",
        "ax2 = ax.twinx()\n",
        "(top_sentiments_df['negative']*(-1)).plot(kind='line', ax=ax2, color='red', marker='o', linewidth=2, label='Negative')\n",
        "\n",
        "# Labels and legend\n",
        "ax.set_xlabel('Food')\n",
        "ax.set_ylabel('Positive Sentiment Value')\n",
        "ax2.set_ylabel('Negative Sentiment Value')\n",
        "ax.set_title('Sentiment Value for Top 20 Entities Sorted by Negative Sentiment')\n",
        "fig.legend(loc='upper right', bbox_to_anchor=(1.1, 1))\n",
        "ax.set_xticklabels(top_sentiments_df.index, rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bCOHhIicJHkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Insights about potential impact on business:\n",
        "-Chicken as a High-Risk Item: While chicken has a relatively high positive sentiment, it has a disproportionately high negative sentiment compared to its positive score. This suggests that chicken dishes are crucial to get right, as they can significantly impact customer sentiment.\n",
        "\n",
        "-Consistency in Service: Service has a high positive sentiment, but also a notable negative sentiment. Consistent service quality could be a determining factor in overall customer satisfaction.\n",
        "\n",
        "-Experience and Taste: These are areas with substantial positive sentiment but also notable negative sentiment. This indicates that while good experiences and taste are praised, bad ones leave a strong negative impression on customers.\n",
        "\n",
        "-Quality Over Speed and Accuracy: Quality has a high positive sentiment and a relatively lower negative sentiment compared to order and time. This implies that customers value the quality of their food over the efficiency of service\n",
        "\n",
        "-Value for Money: Money has a low positive sentiment and a negative sentiment, which suggests that the perception of value for money is a concern for customers.\n",
        "\n",
        "-Operational Aspects: The negative sentiments for 'order', 'delivery', and 'time' are lower than for 'food', 'chicken', and 'place', but are still significant. This could indicate that operational efficiency in order processing and delivery is an area for improvement.\n",
        "\n",
        "-Staff Interaction: Staff have higher positive sentiment and comparatively lower negative sentiment. This suggests that good staff interactions can greatly enhance the customer experience, but poor interactions have less impact on negative sentiment compared to food quality or place.\n",
        "\n",
        "###Business Impact:\n",
        "-Positive Impact:\n",
        "\n",
        "=The data can guide targeted improvements in areas that significantly affect customer sentiment, like food quality and ambiance.\n",
        "\n",
        "=Understanding that quality is more important than speed could lead to prioritizing cooking quality over rapid service, improving overall satisfaction.\n",
        "\n",
        "=Since value for money is a concern, restaurants could review pricing strategies to better align with customer expectations.\n",
        "\n",
        "-Negative Impact:\n",
        "\n",
        "=Failing to address areas with high negative sentiment, especially food and place, could lead to customer loss and negative reviews.\n",
        "\n",
        "=Overlooking the importance of the chicken dishes and experience could disproportionately impact the business negatively due to their high negative sentiments relative to their positive values.\n",
        "\n",
        "\n",
        "Overall, focusing on areas with high positive sentiment can reinforce strengths, while addressing areas with high negative sentiment can mitigate risks. This balance can create a positive business impact by improving customer satisfaction and loyalty.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G0CNedVWJNt_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "# Creating a copy of the dataset for further feature engineering\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# Create a MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "features = mlb.fit_transform(restaurant_data.Cuisines_list)\n",
        "\n",
        "# Create a DataFrame with the cuisine labels\n",
        "features_df = pd.DataFrame(features, columns=mlb.classes_)\n",
        "\n",
        "# Add resataurant name and cost to the features dataFrame\n",
        "features_df['Cost'] = restaurant_data['Cost']\n",
        "features_df['Name'] = restaurant_data['Name']\n",
        "\n",
        "#features_df['avg_rating'] = restaurant_data_ratings['Rating']\n",
        "features_df.set_index('Name', inplace=True)\n",
        "features_df\n"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_df['Avg_Ratings'] = reviews.groupby('Restaurant')['Rating'].mean().sort_values(ascending=False)\n",
        "\n",
        "# Fill Missing Ratings and Cost values with mean\n",
        "features_df['Avg_Ratings'].fillna(value = features_df['Avg_Ratings'].mean(), inplace = True)\n",
        "features_df['Cost'].fillna(value = features_df['Cost'].mean(), inplace = True)\n"
      ],
      "metadata": {
        "id": "q-g2CvGpKfjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only the cuisines that occure more than 7 times\n",
        "selected_features = features_df.columns[features_df.sum(axis=0)>7].tolist()\n",
        "selected_features\n"
      ],
      "metadata": {
        "id": "LiWR7fr2KhPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 Implementing K-Means\n",
        "1. Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "1.Description of the Machine Learning Model and its Effectiveness:\n",
        "\n",
        "-K-Means clustering is the ML model that was utilized. K-Means is a type of unsupervised learning method that clusters data points into K groups depending on their similarity.\n",
        "\n",
        "-Two primary metrics for evaluating the performance of the K-Means model are inertia and silhouette score.\n",
        "\n",
        "-Inertia is the total of squared distances from data points to their nearest cluster centroid. Tighter clusters are indicated by lower inertia values.\n",
        "\n",
        "-The silhouette score gauges an object's resemblance to its cluster versus other clusters. Greater silhouette scores suggest more clearly defined clusters.\n",
        "\n",
        "-Through examining both measures, we can figure out the right amount of clusters that offer a good equilibrium between compact clustering (low inertia) and distinctly separated clusters (high silhouette score).\n",
        "\n",
        "####Many individuals are losing their jobs due to the current economic conditions. What evaluation metrics were taken into account for achieving a positive impact on the business and what was the reasoning behind them?\n",
        "\n",
        "To achieve a positive impact on business, it's important to consider evaluation metrics such as:\n",
        "\n",
        "-Lower values of inertia indicate clusters that are tighter. This means that restaurants in the same cluster share similarities in terms of cuisines and other aspects, allowing for more precise customer recommendations or promotions.\n",
        "\n",
        "-Silhouette Score: This measure shows the extent to which the clusters are distinct from each other. A greater silhouette score indicates clear and distinct clusters, potentially improving restaurant segmentation and allowing for more precise marketing approaches.\n",
        "\n"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#X = features_df\n",
        "X= StandardScaler().fit_transform(features_df[selected_features])\n",
        "\n",
        "# Define a range of cluster numbers to try\n",
        "cluster_range = range(2, 15)  # You can adjust this range as needed\n",
        "\n",
        "# Initialize lists to store the inertia (within-cluster sum of squares) and silhouette scores\n",
        "inertia_values = []\n",
        "silhouette_scores = []\n",
        "\n",
        "# Perform K-means clustering for each cluster number in the range\n",
        "for n_clusters in cluster_range:\n",
        "    kmeans = KMeans(n_clusters=n_clusters,init='k-means++', random_state=42)\n",
        "    kmeans.fit(X)\n",
        "\n",
        "    # Calculate the inertia and silhouette score for this cluster number\n",
        "    inertia_values.append(kmeans.inertia_)\n",
        "    silhouette_scores.append(silhouette_score(X, kmeans.labels_))\n",
        "\n",
        "# Plot the elbow curve to find the optimal number of clusters\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(cluster_range, inertia_values, marker='o')\n",
        "plt.title('Elbow Curve')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Inertia (Within-Cluster Sum of Squares)')\n",
        "\n",
        "# Plot the silhouette score to evaluate cluster quality\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(cluster_range, silhouette_scores, marker='o')\n",
        "plt.title('Silhouette Score')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Silhouette Score')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Based on the plots, you can choose the optimal number of clusters\n",
        "optimal_clusters = cluster_range[np.argmax(silhouette_scores)]\n",
        "print(f\"Optimal number of clusters: {optimal_clusters}\")\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the dendogram to find the optimal number of clusters\n",
        "import scipy.cluster.hierarchy as sch\n",
        "\n",
        "dendrogram = sch.dendrogram(sch.linkage(X, method = 'ward'))\n",
        "plt.title('Dendrogram')\n",
        "plt.xlabel('Customers')\n",
        "plt.ylabel('Euclidean Distances')\n",
        "plt.axhline(y=11.5, color='r', linestyle='--')\n",
        "plt.show() # find largest vertical distance we can make without crossing any other horizontal line"
      ],
      "metadata": {
        "id": "tLioB9ISM2Nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Selected No.of cluster = 7"
      ],
      "metadata": {
        "id": "3FjXnuKKNDmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting hierarchical clustering to the mall dataset\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "# Hierarchical clustering on the t-SNE transformed data\n",
        "hc = AgglomerativeClustering(n_clusters=7, affinity='euclidean', linkage='ward')\n",
        "features_df['Cluster'] = hc.fit_predict(X)"
      ],
      "metadata": {
        "id": "jIeB2nD8NGA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = features_df[selected_features+['Cluster']]\n",
        "results_df\n"
      ],
      "metadata": {
        "id": "UCxDz0NENLfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df_grouped = results_df.groupby('Cluster').sum()\n",
        "results_df_grouped[['Cost','Avg_Ratings']] = results_df[['Cost','Avg_Ratings','Cluster']].groupby('Cluster').mean()\n",
        "results_df_grouped"
      ],
      "metadata": {
        "id": "Cd52RW9fNU0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cuisine Distribution Across Clusters\n",
        "# Preparing the data for heatmap\n",
        "cuisine_data = results_df_grouped.drop(['Cost', 'Avg_Ratings'], axis=1)\n",
        "cost_ratings_data = results_df_grouped[['Cost', 'Avg_Ratings']]\n",
        "\n",
        "# Plotting\n",
        "fig, ax = plt.subplots(2, 1, figsize=(12, 10))\n",
        "\n",
        "# Heatmap for cuisine distribution\n",
        "sns.heatmap(cuisine_data.T, cmap=\"YlGnBu\", ax=ax[0])  # Transposing for better layout\n",
        "ax[0].set_title('Heatmap of Cuisine Distribution Across Clusters')\n",
        "\n",
        "# Grouped bar chart for cost and ratings\n",
        "cost_ratings_data.plot(kind='bar', ax=ax[1], secondary_y='Avg_Ratings')\n",
        "ax[1].set_title('Average Cost and Ratings by Cluster')\n",
        "ax[1].set_ylabel('Cost')\n",
        "ax[1].right_ax.set_ylabel('Avg Ratings')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LIR7Tq-KNbsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Scatterplot of Cost vs Average Ratings with Top 3 Cuisines Labeled\n",
        "df = results_df_grouped.reset_index()\n",
        "\n",
        "# Plotting the scatterplot\n",
        "plt.figure(figsize=(10, 6))\n",
        "for i, row in df.iterrows():\n",
        "    plt.scatter(row['Cost'], row['Avg_Ratings'],s=200, label=f\"{int(row['Cluster'])}\")\n",
        "    top_cuisines = row.drop(['Cluster', 'Cost', 'Avg_Ratings']).nlargest(3)\n",
        "    i = 0\n",
        "    for cuisine, value in top_cuisines.items():\n",
        "        if value > 0:\n",
        "            plt.annotate(cuisine, (row['Cost'], row['Avg_Ratings']), textcoords=\"offset points\", xytext=(30,-20-i*15), ha='center')\n",
        "            i+=1\n",
        "plt.xlabel('Cost')\n",
        "plt.ylabel('Average Ratings')\n",
        "plt.title('Scatterplot of Cost vs Average Ratings with Top 3 Cuisines Labeled')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ASe3DIz7NkgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Ratings to Average cost Ratio\n",
        "ax = (cost_ratings_data.Avg_Ratings/cost_ratings_data.Cost).sort_values(ascending=False).plot(kind='bar', figsize=(10, 6))\n",
        "# Adding labels and title\n",
        "plt.title('Ratings to Average Cost Ratio by Cluster')\n",
        "plt.xlabel('Cluster')\n",
        "plt.ylabel('Ratio')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Show plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_gi1MUjXNnPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_vDPeJ6jnj32"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cluster Analysis\n",
        "-Cluster 1 is characterized by its affordability and a high rating-to-cost ratio. This group of restaurants offers a diverse range of cuisines, including desserts, continental food, biryani, and Chinese, suggesting that they provide a good mix of quality, affordability, and variety.\n",
        "\n",
        "-Cluster 2 boasts the top average cost and ratings, suggesting it comprises upscale restaurants providing top-notch quality and service. The food in this group consists mostly of Italian and Asian dishes, indicating that these are well-liked and lucrative options for high-end restaurants.\n",
        "\n",
        "-Cluster 5 has the second highest average ratings, yet its cost is lower than that of cluster 2. The majority of eateries in this group are Asian restaurants, suggesting that this type of cuisine is popular and reasonably priced among patrons. This grouping also includes several continental and Chinese eateries, catering to a wide variety of tastes and preferences.\n",
        "\n",
        "-Cluster 4 has the cheapest average ratings, but a decent cost. This group has an abundance of biryani and Chinese eateries, perhaps suggesting that these types of cuisine are either oversaturated or not doing well in the market. The poor ratings could be a result of the restaurants' quality, service, or hygiene problems.\n",
        "\n",
        "-Cluster 6 has the lowest average cost, but also low ratings. This cluster consists mostly of fast food restaurants, which may cater to the budget-conscious or time-pressed customers. However, the low ratings may suggest that these restaurants do not offer much value or satisfaction to the customers.\n",
        "\n",
        "-Cluster 0 and 3 have similar costs and ratings, but different cuisines. Cluster 0 has mostly north Indian and Chinese restaurants, while cluster 3 has mostly south Indian and continental restaurants. These clusters may reflect the regional and cultural preferences of the customers, as well as the availability and competition of these cuisines in the market.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Summary of Business Case Solutions Based on Insights:\n",
        "1.Improving Food and Location Experiences:\n",
        "\n",
        "-Invest in enhancing the quality and atmosphere of restaurants to target the prevalent negativity linked to food and environment.\n",
        "\n",
        "2.Strategic Method for Chicken Recipes:\n",
        "\n",
        "-Develop a thorough evaluation and enhancement plan tailored to chicken recipes, considering their significant influence on both favorable and unfavorable opinions.\n",
        "\n",
        "3.Giving importance to maintaining a consistent level of service quality:\n",
        "\n",
        "-Create and execute training programs for employees to maintain uniform service quality, taking into account its impact on overall customer happiness.\n",
        "\n",
        "4.Achieving a balance between flavor and expertise.\n",
        "\n",
        "-Perform frequent quality inspections to uphold favorable feelings regarding flavor and experience, minimizing the repercussions of occasional errors.\n",
        "\n",
        "The insights have led to the development of targeted business solutions designed to help Zomato and its partner restaurants improve in key areas, enhance customer satisfaction, and promote sustainable growth."
      ],
      "metadata": {
        "id": "5Tp3MgA47bjR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}